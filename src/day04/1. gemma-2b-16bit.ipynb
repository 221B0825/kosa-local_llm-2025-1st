{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q -U transformers\n",
    "!pip3 install -q -U datasets\n",
    "!pip3 install -q -U bitsandbytes\n",
    "!pip3 install -q -U peft\n",
    "!pip3 install -q -U trl\n",
    "!pip3 install -q -U accelerate\n",
    "!pip3 install -q -U jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, TrainingArguments\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13df7803b90f4289adedec6c38cbe064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9bbd3b67e0b4d64b23a9d2eb357726c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7d8447be514f33a9a77fd0d449e8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853414f64ddd45e79639422cbf4c49cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82fa1652ce5c46d5a7d2cc9b99aa2726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/618 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dbb7a0e0e524dfc89cc8c39b9467a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e42e150e294e7ca4b94b9c7770ce34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f314bd4265564dfcba7355384a0cdfe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340d0782293b4bd6b829a7ec24f52102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0faa0591eda4c3584fa533f545c3cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1fc99f3f5841a1aa8fb380f711379c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-1.1-2b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-1.1-2b-it\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    "#    device_map={\"\":0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Write me a poem about Machine Learning.\n",
      "\n",
      "In circuits of code, a mind takes form,\n",
      "A tapestry of algorithms, a digital storm.\n",
      "Through layers of computation, data takes flight,\n",
      "Learning patterns, insights in the night.\n",
      "\n",
      "From images that speak, to algorithms that bind\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Write me a poem about Machine Learning.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=50)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "이순신 장군에 대해 설명해주세요.<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_gen = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens = 512\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"이순신 장군에 대해 설명해주세요.\"},\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**이순신 장군**은 조선의 제10대 장군으로, 1592년 조선을 건국한 것으로 알려져 있습니다.\n",
      "\n",
      "**생애:**\n",
      "\n",
      "* 1557년 3월 18일, 경기도 양평에서 출생했습니다.\n",
      "* 조선의 13대 군주 조선왕의 막내로 출생했습니다.\n",
      "* 1582년 조선을 건국했습니다.\n",
      "\n",
      "**장군 활동:**\n",
      "\n",
      "* 조선을 건국한 후, 이순신은 조선의 군사적, 정치적, 경제적 권력을 확대했습니다.\n",
      "* 조선을 국경으로 넘어 일본, 한국, 일본 등 지역을 점령했습니다.\n",
      "* 조선의 문화와 경제를 발전시켰습니다.\n",
      "\n",
      "**사후:**\n",
      "\n",
      "* 이순신은 조선의 첫 번째 대통령이되었습니다.\n",
      "* 그의 영향은 조선의 역사에 지대한 영향을 미했습니다.\n",
      "* 그의 이름은 조선의 국민의 이름으로 유명합니다.\n",
      "\n",
      "**주요 업적:**\n",
      "\n",
      "* 조선을 건국\n",
      "* 조선의 군사적, 정치적, 경제적 권력 확대\n",
      "* 조선의 문화와 경제 발전\n",
      "* 조선의 국민들에게 영감을 줄 힘을 제공\n"
     ]
    }
   ],
   "source": [
    "outputs = text_gen(\n",
    "    prompt,\n",
    "    max_new_tokens=4096,\n",
    "    add_special_tokens=True\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer, GenerationConfig\n",
    "\n",
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "def gen(prompt):\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature = 1.31,\n",
    "        max_new_tokens = 512,\n",
    "        exponential_decay_length_penalty = (512, 1.03),\n",
    "        eos_token_id = tokenizer.eos_token_id,\n",
    "        repetition_penalty = 1.17,\n",
    "        do_sample = True,\n",
    "        top_k = 49,\n",
    "        top_p = 0.14,\n",
    "        min_length = 5,\n",
    "        use_cache = True,\n",
    "        return_dict_in_generate = True\n",
    "    )\n",
    "    gened = model.generate(\n",
    "        **tokenizer(\n",
    "            prompt,\n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids=False\n",
    "        ).to(\"cuda\"),\n",
    "        generation_config=generation_config,\n",
    "        streamer=streamer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`generation_config` default values have been modified to match model-specific defaults: {'pad_token_id': 0, 'bos_token_id': 2, 'transformers_version': '4.38.1'}. If this is not desired, please set these values explicitly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><bos><start_of_turn>user\n",
      "이순신 장군에 대해 설명해주세요.<end_of_turn>\n",
      "<start_of_turn>model\n",
      "**이순신 장군**은 조선의 제10대 장군으로, 1592년부터 1608년까지 재위했습니다. 그는 조선의 군사적 지도와 정치적 권력을 확장하는 데 큰 기여를했습니다.\n",
      "\n",
      "**생애:**\n",
      "\n",
      "* 1573년 문종이 조선을 건국한 후, 이순신은 조선의 장수로서 활동했습니다.\n",
      "* 1592년, 조선을 방문하여 조선의 군사적 강력함을 증명했습니다.\n",
      "* 1598년, 조선을 북쪽으로 침략하여 동북 지역을 점령했습니다.\n",
      "\n",
      "**지도:**\n",
      "\n",
      "* 이순신은 조선의 군사적 지도자로, 조선의 전략적 위치를 개선하고 군사적 전략을 개선했습니다.\n",
      "* 그는 조선의 군사적 우위를 높였고, 조선의 영역을 넓혔습니다.\n",
      "* 그는 또한 조선의 정치적 권력을 확장하고, 조선의 통제권을 강화했습니다.\n",
      "\n",
      "**기여:**\n",
      "\n",
      "* 조선의 군사적 강력함을 높입니다.\n",
      "* 조선의 영역을 넓힙니다.\n",
      "* 조선의 정치적 권력을 확장합니다.\n",
      "* 조선의 역사에 중요한 역할을 합니다.\n",
      "\n",
      "**영향:**\n",
      "\n",
      "* 이순신은 조선의 역사에 큰 영향을 미쳤습니다.\n",
      "* 그의 지도는 조선의 군사적 강력함과 정치적 권력을 높입니다.\n",
      "* 그의 이름은 조선의 장군으로 유명하며, 그의 이름은 조선의 국민들에게 전통적인 이미지를 제공합니다.<eos>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"이순신 장군에 대해 설명해주세요.\"},\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True) \n",
    "\n",
    "gen(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer\n",
    "from threading import Thread\n",
    "\n",
    "def gen(prompt):\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "    streamer = TextIteratorStreamer(tokenizer)\n",
    "\n",
    "    generation_kwargs = dict(inputs, streamer=streamer, max_new_tokens=256)\n",
    "    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "    thread.start()\n",
    "    return streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**이순신 장군**은 조선의 제10대 장군으로, 1592년 조선을 건국한 것으로 알려져 있습니다.\n",
      "\n",
      "**생애:**\n",
      "\n",
      "* 1557년 3월 18일, 경기도 양평에서 출생했습니다.\n",
      "* 조선의 13대 군주 조선왕의 막내로 출생했습니다.\n",
      "* 1582년 조선을 건국했습니다.\n",
      "\n",
      "**장군 활동:**\n",
      "\n",
      "* 조선을 건국한 후, 이순신은 조선의 군사적, 정치적, 경제적 권력을 확대했습니다.\n",
      "* 조선을 국경으로 넘어 일본, 한국, 일본 등 지역을 점령했습니다.\n",
      "* 조선의 문화와 경제를 발전시켰습니다.\n",
      "\n",
      "**사후:**\n",
      "\n",
      "* 이순신은 조선의 첫 번째 대통령이되었습니다.\n",
      "* 그의 영향은 조선의 역사에 지대한 영향을 미했습니다.\n",
      "* 그의 이름은 조선의 국민의 이름으로 유명합니다.\n",
      "\n",
      "**주요 업적:**\n",
      "\n",
      "* 조"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"이순신 장군에 대해 설명해주세요.\"},\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True) \n",
    "\n",
    "streamer = gen(prompt)\n",
    "is_first_chunk = True\n",
    "for text in streamer:\n",
    "    if is_first_chunk:\n",
    "        is_first_chunk = False\n",
    "        continue\n",
    "    print(text, end='')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
